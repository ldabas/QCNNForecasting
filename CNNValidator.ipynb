{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNValidator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qt6ynHWvGFo"
      },
      "source": [
        "global in_sample_dataset\n",
        "global out_sample_dataset\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHJg2gu-UCKy"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Dense, Flatten, Conv1D\n",
        "import pandas as pd\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.multivariate.pca import PCA\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from math import sqrt\n",
        "from statsmodels.tsa.api import ExponentialSmoothing\n",
        "from statsmodels.tsa.holtwinters import SimpleExpSmoothing, Holt\n",
        "from statsmodels.tsa.api import VAR\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "sns.set(rc={'figure.figsize':(8.7,6.27)})\n",
        "\n",
        "from numpy import array\n",
        "from numpy import hstack\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.layers import LeakyReLU\n",
        "\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsmvpyUkXiSQ",
        "outputId": "f9543a3c-4807-473b-802f-a9b4a1fc18d0"
      },
      "source": [
        "!unzip testmodel.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  testmodel.zip\n",
            "replace saved_models/my_model/keras_metadata.pb? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: saved_models/my_model/keras_metadata.pb  \n",
            "replace saved_models/my_model/variables/variables.data-00000-of-00001? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: saved_models/my_model/variables/variables.data-00000-of-00001  \n",
            "replace saved_models/my_model/variables/variables.index? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: saved_models/my_model/variables/variables.index  \n",
            "replace saved_models/my_model/saved_model.pb? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: saved_models/my_model/saved_model.pb  \n",
            "replace saved_models/discrete/keras_metadata.pb? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: saved_models/discrete/keras_metadata.pb  \n",
            "replace saved_models/discrete/variables/variables.data-00000-of-00001? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: saved_models/discrete/variables/variables.data-00000-of-00001  \n",
            "replace saved_models/discrete/variables/variables.index? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: saved_models/discrete/variables/variables.index  \n",
            "replace saved_models/discrete/saved_model.pb? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: saved_models/discrete/saved_model.pb  \n",
            "   creating: saved_models/classical_discrete/\n",
            "   creating: saved_models/classical_discrete/assets/\n",
            "  inflating: saved_models/classical_discrete/keras_metadata.pb  \n",
            "   creating: saved_models/classical_discrete/variables/\n",
            "  inflating: saved_models/classical_discrete/variables/variables.data-00000-of-00001  \n",
            "  inflating: saved_models/classical_discrete/variables/variables.index  \n",
            "  inflating: saved_models/classical_discrete/saved_model.pb  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoeZRXJ2U3Nu"
      },
      "source": [
        "new_model = tf.keras.models.load_model('saved_models/discrete')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84g4jsl2ho5y"
      },
      "source": [
        "class UndefinedModelError(Exception):\n",
        "    \"\"\"Please input either 'discrete' or 'time-window' as model type\"\"\"\n",
        "    def __init__(self, message=\"Please input either 'discrete' or 'time_window' as model type\"):\n",
        "        self.message = message\n",
        "        super().__init__(self.message)\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "zdQDTLToYo1x",
        "outputId": "b499317c-9bfd-459a-8692-fd3657a89c37"
      },
      "source": [
        "def get_metrics(errors, actual, predicted, name, sample):\n",
        "  errors = np.array(errors)\n",
        "  mape = np.mean(np.abs(errors)/actual)\n",
        "  accuracy = 100- (100*mape)\n",
        "  rmse = np.sqrt(np.mean((np.square(errors))))\n",
        "  rmse_percent = rmse/np.mean(actual)\n",
        "  mae = np.mean(np.abs(errors))\n",
        "  mae_percent = np.mean(np.abs(errors))/np.mean(actual)\n",
        "  metrics = {\"MAPE\":[mape], \"Accuracy%\":[round(accuracy, 2)], \n",
        "             \"RMSE\": [round(accuracy, 2)], \"RMSE%\": [round(100*rmse,2)], \n",
        "             \"MAE\":[round(mae,2)], \"MAE%\":[round(100*mae,2)]}\n",
        "\n",
        "  metrics_df = pd.DataFrame.from_dict(metrics)\n",
        "  filename = sample+ \"_\"+ name+ \"_performance_metrics\"\n",
        "  print(filename)\n",
        "  metrics_df.to_csv(filename+\".csv\")\n",
        "  return filename\n",
        "  \n",
        "def make_visualisations(errors, actual, predicted, filename):\n",
        "  results = pd.DataFrame(columns=[\"Expected\", \"Predicted\"])\n",
        "  results[\"Expected\"] = actual\n",
        "  #results[\"Expected_Trend\"] = results['Expected'].rolling(3).mean()\n",
        "\n",
        "  results[\"Predicted\"] = predicted\n",
        "  #results[\"Predicted_Trend\"] = results['Predicted'].rolling(3).mean()\n",
        "\n",
        "  #plt.ylim(0,5)\n",
        "  sns.set(rc={'figure.figsize':(12.7,6.27)})\n",
        "  sns.lineplot(data=results,palette=\"deep\").set_title(filename)\n",
        "  plt.savefig(filename + \".png\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def show_plot(plot_data, delta, title):\n",
        "    labels = [\"History\", \"True Future\", \"Model Prediction\"]\n",
        "    marker = [\".-\", \"rx\", \"go\"]\n",
        "    time_steps = list(range(-(plot_data[0].shape[0]), 0))\n",
        "    if delta:\n",
        "        future = delta\n",
        "    else:\n",
        "        future = 0\n",
        "\n",
        "    plt.title(title)\n",
        "    for i, val in enumerate(plot_data):\n",
        "        if i:\n",
        "            plt.plot(future, plot_data[i], marker[i], markersize=10, label=labels[i])\n",
        "        else:\n",
        "            plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
        "    plt.legend()\n",
        "    plt.ylim([0, 5])\n",
        "    plt.xlim([time_steps[0], (future + 5) * 2])\n",
        "    plt.xlabel(\"Time-Step\")\n",
        "    plt.show()\n",
        "    return\n",
        "\n",
        "def make_predictions_in_sample(in_sample_dataset, model):\n",
        "  errors = []\n",
        "  actual = []\n",
        "  predicted = []\n",
        "  for x, y in in_sample_dataset.take(200):\n",
        "    # show_plot(\n",
        "    #     [x[0][:, 4].numpy(), y[0].numpy(), model.predict(x)[0]],\n",
        "    #     1,\n",
        "    #     \"Single Step Prediction\",\n",
        "    # )\n",
        "\n",
        "    errors.append(y[0].numpy()[0]- model.predict(x)[0][0])\n",
        "\n",
        "    actual.append(y[0].numpy()[0])\n",
        "    predicted.append(model.predict(x)[0][0])\n",
        "  return errors, actual, predicted\n",
        "\n",
        "def make_predictions_out_sample(model):\n",
        "  errors = []\n",
        "  actual = []\n",
        "  predicted = []\n",
        "  for x, y in out_sample_dataset.take(200):\n",
        "    show_plot(\n",
        "        [x[0][:, 4].numpy(), y[0].numpy(), model.predict(x)[0]],\n",
        "        1,\n",
        "        \"Single Step Prediction\",\n",
        "    )\n",
        "\n",
        "    errors.append(y[0].numpy()[0]- model.predict(x)[0][0])\n",
        "\n",
        "    actual.append(y[0].numpy()[0])\n",
        "    predicted.append(model.predict(x)[0][0])\n",
        "  return errors, actual, predicted\n",
        "\n",
        "def eval_cnn(type = None):\n",
        "  if type =='discrete':\n",
        "    past = 1\n",
        "  elif type=='time_window':\n",
        "    past = 3\n",
        "  else:\n",
        "    raise UndefinedModelError\n",
        "  \n",
        "  step = 1\n",
        "  sequence_length = int(past / step)\n",
        "  in_sample_data = pd.read_csv(\"in_sample.csv\",index_col=0)\n",
        "  in_sample_x = in_sample_data[[\"0\",\"1\",\"2\",\"3\",\"5\"]].values\n",
        "  in_sample_y = in_sample_data[[\"4\"]].values\n",
        "  out_sample_data = pd.read_csv(\"out_sample.csv\",index_col=0)\n",
        "  out_sample_x = in_sample_data[[\"0\",\"1\",\"2\",\"3\",\"5\"]].values\n",
        "  out_sample_y = in_sample_data[[\"4\"]].values\n",
        "\n",
        "\n",
        "  in_sample_dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
        "    in_sample_x,\n",
        "    in_sample_y,\n",
        "    sequence_length=sequence_length,\n",
        "    sampling_rate=step,\n",
        "    )\n",
        "  \n",
        "  \n",
        "  model_name = \"saved_models/classical_\"+type\n",
        "  model = tf.keras.models.load_model(model_name)\n",
        "  errors, actual, predicted = make_predictions_in_sample(in_sample_dataset, model)\n",
        "  name = \"classical_\"+type\n",
        "  filename = get_metrics(errors, actual, predicted, name, \"in_sample\")\n",
        "  \n",
        "\n",
        "  out_sample_dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
        "    out_sample_x,\n",
        "    out_sample_y,\n",
        "    sequence_length=sequence_length,\n",
        "    sampling_rate=step,\n",
        "    )\n",
        "  \n",
        "  \n",
        "  errors, actual, predicted = make_predictions_out_sample(model)\n",
        "  filename = get_metrics(errors, actual, predicted, name, \"out_of_sample\")\n",
        "\n",
        "\n",
        "eval_cnn(\"discrete\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "in_sample_classical_discrete_performance_metrics\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-ffee9c605ec3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m \u001b[0meval_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"discrete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-ffee9c605ec3>\u001b[0m in \u001b[0;36meval_cnn\u001b[0;34m(type)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m   \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_predictions_out_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m   \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"out_of_sample\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-ffee9c605ec3>\u001b[0m in \u001b[0;36mmake_predictions_out_sample\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     76\u001b[0m   \u001b[0mactual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout_sample_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     show_plot(\n\u001b[1;32m     80\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'out_sample_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "qoQ7rPc0ZIAe",
        "outputId": "495fb7b0-63fc-41f8-94c7-b6d8dba1ee8f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "in_sample_saved_models/classical_discrete_performance_metrics\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-cca2aa98c7f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"discrete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-00c47ffb5cfb>\u001b[0m in \u001b[0;36meval_cnn\u001b[0;34m(type)\u001b[0m\n\u001b[1;32m    118\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m   \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_predictions_in_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_sample_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m   \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"in_sample\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-00c47ffb5cfb>\u001b[0m in \u001b[0;36mget_metrics\u001b[0;34m(errors, actual, predicted, name, sample)\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m\"_performance_metrics\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mmetrics_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[1;32m   3168\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3169\u001b[0m         )\n\u001b[0;32m-> 3170\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                 \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m             )\n\u001b[1;32m    192\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'in_sample_saved_models/classical_discrete_performance_metrics.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnAb1adLd0eC"
      },
      "source": [
        "metrics = pd.DataFrame(columns=[])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}